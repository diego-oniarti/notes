\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{algorithm2e}
\usepackage[symbol]{footmisc}
\usepackage{cancel}
\usepackage{amssymb}

\RestyleAlgo{ruled}

\usepackage{lipsum}
\input{../common}

\newcommand{\floor}[1]{\ensuremath{\lfloor #1 \rfloor}}
\newcommand{\tvs}[0]{\text{\textvisiblespace}}
\newcommand{\N}[0]{\ensuremath{\mathbb{N}}}

\usepackage{tikz}
\usetikzlibrary{tikzmark,calc,,arrows,shapes,decorations.pathreplacing}
\tikzset{every picture/.style={remember picture}}
\usepackage{accents}
\newcommand\myubar[1]{%
\underaccent{\bar}{#1}}
\title{Appunti Computability}
\author{Diego Oniarti}
\date{Anno 2024-2025}

\begin{document}

\maketitle
\tableofcontents

\section{Macchina di Turing}
Una macchina di Turing è rappresentata da:
\begin{itemize}
    \item $\Sigma=\{\sigma_0,\dots,\sigma_{m-1}\}$
    \item $Q=\{q_0, \dots, q_{n-1}\}$
    \item $q_o \in Q$ stato iniziale
    \item $f:\Sigma\times Q \to \Sigma\times Q\times \{\leftarrow,\rightarrow\}$
\end{itemize}
La funzione di transizione può essere definita come una tabella

\[
    Q \left\{
        \begin{array}{|c|c|c|c|}
            \hline
            & \sigma_0 &\cdots& \sigma_n \\
            \hline
            q_0 & & \\
            \hline
            \vdots & & \\
            \hline
            q_n & & \\
            \hline
        \end{array}
    \right.
\]
Un altra rappresentazione per una macchina di Turing è quella della macchina a stati (come quelle viste in LFC). Gli stati corrispondono agli stati della macchina di Turing, mentre le transizioni contengono il carattere letto, quello da scrivere, e la transizione.

\begin{callout}{NB}
    Come definiamo la funzione di transizione non è importante. Per la definizione di una macchina di Turing basta che esista una funzione di transizione del tipo $f:\Sigma\times Q \to \Sigma\times Q\times \{\leftarrow,\rightarrow\}$

    Non è necessario che la funzione di transizione sia totale.
\end{callout}

\paragraph{Esempio}
Questa è la funzione di transizione per una macchina di Turing che inizia con un numero binario sul nastro e ci aggiunge $1$.
\[
    \begin{array}{c|c|c|c}
        & \textvisiblespace & 0 & 1 \\
        \hline
        LSB & \textvisiblespace,carry,\leftarrow & 0,LSB,\rightarrow & 1,LSB,\rightarrow \\
        carry & 1,MSB,\leftarrow& 1,MSB,\leftarrow& 0,carry,\leftarrow\\
        MSB & \textvisiblespace,halt,\rightarrow & 0,MSB,\leftarrow & 1,MSB,\leftarrow
    \end{array}
\]

\paragraph{Esempio}
Ideiamo una macchina di Turing che inizia con un numero sul nastro. La macchina deve:
\begin{itemize}
    \item creare una copia del numero letto
    \item scrivere questa copia a destra del numero dato
    \item lasciare il numero intoccato
    \item lasciare un \textvisiblespace\ tra i due numeri
\end{itemize}

Una soluzione valida sarebbe questa, dove l'alfabeto è $\Sigma=\{\text\textvisiblespace,0,1,\hat 0, \hat 1\}$ e la funzione di transizione è:
\[
    \begin{array}{c|c|c|c|c|c}
        & \textvisiblespace & 0 & 1 & \hat 0 & \hat 1 \\
        \hline
        next & \textvisiblespace,halt,\rightarrow & \hat 0,first0,\rightarrow &\hat 1,first1,\rightarrow & & \\
        first1 & \textvisiblespace,scom1,\rightarrow & 0,first1,\rightarrow & 1,scom1,\rightarrow & & \\
        scom1 & 1,left,\leftarrow & 0,scom1,\rightarrow & 1,scom1,\rightarrow & & \\
        first0 & \textvisiblespace,scom0,\rightarrow & 0,first0,\rightarrow & 1,scom0,\rightarrow & & \\
        scom0 & 0,left,\leftarrow & 0,scom0,\rightarrow & 1,scom0,\rightarrow & & \\
        left & \textvisiblespace,left,\leftarrow & 0,left,\leftarrow & 1,left,\leftarrow & 0,next,\rightarrow & 1,next,\rightarrow \\

    \end{array}
\]

\section {Multi-Tape Turing Machine}\label{sec: multitape}
Per convenzione immaginiamo una macchina con un tape di input, uno di output, e gli altri sono per utilizza arbitrario. \\
Ogni tape ha un puntatore suo, e può decidere di muoverlo o lasciarlo intoccato.
La funzione di transizione prende questa forma
\large\[
    f: \Sigma^t\times Q \to \Sigma^t\times Q \times \{\leftarrow, \downarrow, \rightarrow\}^t
\]
\normalsize
dove l'apice $t$ (numero di tape) indica che l'elemento è ripetuto $t$ volte all'interno di una tupla. \\
La funzione quindi prende l'input di tutti i tape e lo stato corrente. Questo decide cosa scrivere in ogni tape, lo stato a cui muoversi, e la direzione in cui muovere ogni tape.

\paragraph{Multi-Tape vs Single Tape}
Una macchina di Turing con più tape può svolgere le stesse computazioni di una macchina a tape singolo. È solo più veloce a farlo.

\section{Turing vs Universal Machines}
Una differenza che rimane tra la macchina di Turing descritta e un computer come lo vediamo oggi è la seguente. Una macchina di Turing è hard coded per svolgere un singolo compito.

Possiamo quindi formalizzare una macchina di Turing $U$ che sia universale? sì. \\
L'input di $U$ deve essere un encoding di una macchina $m$.

Prendiamo per esempio la macchina di Turing che aggiunge $1$ ad un numero (vista in precedenza).
\[
    \begin{array}{c|c|c|c}
        & \textvisiblespace & 0 & 1 \\
        \hline
        0 & \textvisiblespace,1,\leftarrow & 0,0,\rightarrow & 1,0,\rightarrow \\
        1 & 1,H & 1, H & 0,1,\leftarrow
    \end{array}
\]
Possiamo definire un'alfabeto che ci permetta di descrivere questa tabella sotto forma di stringa.
\begin{align*}
    \Sigma &= \{\text{\textvisiblespace},1,0,',',;\} \\
    \text{tabella}&=\text{\textvisiblespace},1,0;0,0,1;1,0,1;1,,;1,,;0,1,0
\end{align*}
Prendiamo cone convenzione che ogni cella sia definita da 3 simboli separati da virgole. Un simbolo mancante è interpretato come l'\textit{Halting State}.

La macchina universale $U$ è composta da:
\begin{itemize}
    \item Un tape $\lfloor m\rfloor$ che rappresenta la macchina $m$
    \item Un tape $s$ che rappresenta lo stato di $m$
    \item Uno o più tape usati per l'esecuzione di $m$
\end{itemize}
\begin{callout}{nb}
    Come detto in Sec.\ref{sec: multitape}, questo può essere svolto anche con una macchina a tape singolo.
\end{callout}
L'esecuzione di $m$ utilizzando $U$ richiede più \textit{step} dell'esecuzione di $m$. Ma il numero di step di $U$ scala linearmente con quello di $m$.

\begin{align*}
    t(m,s) &\leq 2|s|+1 \\
    t(U,\lfloor m \rfloor s) &\leq k t(m,s) \\
\end{align*}
dove $t(a,b)$ è il tempo di esecuzione della macchina $a$ sull'input $b$.

\subsection{Random-access Machine}
Un computer moderno può essere definito come una "\textit{random access machine}" in quanto accede agli indirizzi di memoria in tempo costante, a differenza della macchina di Turing che deve scorrere il tape.\\
Questa è l'unica differenza tra i due tipi di macchine. Quella di Turing è "lenta".

Ogni altro aspetto di una CPU odierna può essere creato analogamente in una macchina di Turing (Pc, registri, memoria, etc..).

\subsection*{Nota sull'alfabeto}
Abbiamo usato un alfabeto $\Sigma$ di 5 caratteri per descrivere la Turing machine, ma potremmo rappresentare ogni simbolo con un numero binario a tre cifre. Questo ci permette di descrivere un programma come una stringa binaria.

\section{Uncomputable machines}
Possiamo rappresentare ogni possibile macchina di Turing e ogni può output in una tabella
\[
    TM\left\{\overbrace{\begin{array}{c|c c c c c}
            & \epsilon & 0 & 1 & 00 & \cdots \\
            \hline
        \epsilon & \\
        0   &  \\
        1 & \\
        \vdots & 

    \end{array}}^{\Sigma^*}\right.
\]
\begin{align*}
    & UC: \Sigma^*\mapsto\{0,1\} \\
    & UC(\alpha) = \begin{cases}
        0 & m_\alpha(\alpha)=1 \\
        1 & \text{altrimenti}
    \end{cases} \\
    & m_\alpha \text{ macchina descritta dalla stringa } \alpha
\end{align*}
Ora possiamo usare l'argomento della diagonale per creare una macchina $UC$ che non sia computabile.

\paragraph{Thesis}
\[
    \forall m\in TM \exists s \in \{0,1\}^*:\ m(s)\neq UC(s)
\] 

\begin{callout}{}
    Sapevamo già che esistessero problemi non calcolabili. Questa è sono un'altra prova.
    \begin{align*}
        UC\in\{f:\Sigma^*\to\{0,1\}\} &\quad \text{uncountable} \\
        \{TM\} &\quad \text{countable}
    \end{align*}
\end{callout}

\begin{callout}{Congettura di Goldbach}
    Ogni numero maggiore di due può essere espresso come la somma di due numeri primi.
\end{callout}

\subsection{Halting Problem}
Esiste una macchina $H(\floor{M},\epsilon)$ che so comporti così?
$$
H(\floor{M},\epsilon) = \begin{cases}
    1 & M(\epsilon)\ \text{halts} \\
    0 & M(\epsilon)\ \text{does not halt} 
\end{cases}
$$

No. Se esistesse esisterebbe anche la macchina $H'$ con questo comportamento.
$$
H'(\floor{M},\epsilon) = \begin{cases}
    0 & H(\floor{M},\epsilon)==1 \\
    \infty & H(\floor{M},\epsilon)==0
\end{cases}
$$
Il comportamento di $H(H'(\floor{M},\epsilon))$ non può poi essere definito.

\begin{warning}{NB}
    Questa non è la dimostrazione usata dal prof. Per quella chiedi in giro.
\end{warning}

\subsubsection{rambling}
Halt non è ricorsiva. Halt è ricorsivamente enumerabile? Si. Basta usare il metodo "parallelo" diagonale visto in precedenza. (avanzare tutti i casi di uno step alla volta)
faccio un backup

\section{Recap}
\subsection{Insiemi}
Abbiamo due modi di definire un subset ti tutte le stringhe.
\begin{align*}
    s &\subseteq \Sigma^* \\
    f:\Sigma^*&\to\{0,1\} \\
\end{align*}

\subsection{recursive}
Un set è \textit{recursive} se e solo se
\begin{align*}
    s\in R \iff \exists m\ TM\ s.t. \forall x\in\Sigma^*\ m(x)=\begin{cases}0&x\not\in s \\ 1 & x\in s\end{cases}
\end{align*}

\subsection{Recursively Enumerable}
Ci sono tre modi di definire $RE$.
\begin{itemize}
    \item Un set è ricorsivamente enumerabile se:
        \begin{align*}
            s\in RE \iff \exists m\ TM\ s.t. \forall x\in\Sigma^*\ m(x)=\begin{cases}1&x\in s \\ \text{anything else} & x\not\in s\end{cases}
        \end{align*}
        \textit{Anything Else} include anche il non haltare mai.

    \item
        \begin{align*}
            \forall x\in\Sigma^* m(x)=\begin{cases}1&x\in s \\ \infty & x\not\in s\end{cases}
        \end{align*}

    \item $m$ scrive su un tape tutti e soli gli elementi di $s$.
\end{itemize}
Possiamo dimostrare che le 3 definizioni sono equivalenti.
\begin{itemize}
    \item $2\implies 1$: Triviale. $\infty\in\text{Anything Else}$
    \item $1\implies 2$: Assumendo di avere una macchina $m_1$, possiamo costruire una macchina $m_2$.
        \begin{align*}
            m_2(x) = \begin{cases}
                1 & m_1(x) = 1 \\
                \infty & otherwise
            \end{cases}
        \end{align*}
        Questa tecnica di prendere una macchina e modificarla per crearne un'altra è chiamata \textbf{riduzione}.
    \item $2\implies 3$: Assumiamo di avere $m_2$.
        \begin{align*}
            & queue \leftarrow empty \\
            & \forall x \in \Sigma^*: \\
            & \quad queue.push\ (x, \text{init configuration of }m_2(x)) \\
            & \quad \forall (y,\text{configuration of }m_2(y)) \in q: \\
            & \quad\quad if\ \text{configuration is halted}: \\
            & \quad\quad\quad \text{output }y \\
            & \quad\quad\quad \text{remove from queue} (y,config) \\
            & \quad\quad else: \\
            & \quad\quad\quad \text{advance configuration by one step} \\
        \end{align*}
        \begin{callout}{Diagonale}
            Questo è a tutti gli effetti un ennesimo utilizza del metodo diagonale.
        \end{callout}
\end{itemize}

\subsection{coRE}
Un set è Co recursively enumerable (coRE) se il suo complementare è ricorsivamente enumerabile.

\begin{align*}
    s\in RE && m(x) = \begin{cases}
        1 & x\in S \\
        \text{anything else} & x\not\in S
    \end{cases} 
    \\
        s\in coRE && m(x) = \begin{cases}
        0 & x\not\in S \\
        \text{anything else} & x\in S
    \end{cases}
    \\
        s\in coRE && \overline{m(x)} = \begin{cases}
        0 & x\not\in S \\
        \infty & x\in S
    \end{cases}
\end{align*}

\begin{callout}{Set}
    Dato il powerset di $\Sigma^*$ (tutte le stringhe), $RE$ e $coRE$ sono due sottoinsiemi di $P(\Sigma^*)$. $R$ (linguaggi ricorsivi) \textbf{è} l'intersezione di $RE$ e $coRE$.
\end{callout}

\section{Ordering}
Sia dato un linguaggio $L\subseteq \Sigma^*$ e un ordinamento $<$. Assumiamo che $L$ sia ricorsivamente enumerabile ma non ricorsivo $L\in RE\setminus R$.
Essendo $L$ in $RE$, esiste una macchina $m$ che produce tutti gli elementi di $L$. Possiamo provare che non esiste una macchina che li produce in ordine.

\section{boh}
\begin{align*}
    HALT &= \{(t,s): m_t(s)\neq\infty\} \in RE\setminus R \\
    HALT_\epsilon &= \{t: m_t(\epsilon)\neq\infty\} \not\in R
\end{align*}

Ipotizziamo per assurdo che $H_\epsilon$ sia ricorsiva.
\begin{align*}
    H_\epsilon: \Sigma^*&\to\{0,1\} \\
    t &\mapsto \begin{cases}
        1 & m_t(s)\text{ halts} \\
        0 & \text{otherwise} \\
    \end{cases}
\end{align*}
\begin{warning}{AO}
    mi sono distratto e non ho seguito. Però la prova funziona per riduzione e contraddizione. Crea una macchina $H$ che scrive un input e chiama $H_\epsilon$ mi pare
\end{warning}

\section{Busy beaver "game"}
\begin{align*}
    |\Sigma| &= n \\
    |Q| &= m \\
    halt &\not\in Q
\end{align*}
Il numero di macchine possibili con questi parametri è $2n^2m(m+1)$. Si può vedere questo costruendo la tabella che definisce le transizioni della macchina.

Chiamiamo $\Sigma(m)$ Il numero massimo di 1 che una macchina con $m$ stati può mettere sul tape.  \\
Poi chiamiamo $S(m)$ il numero massimo di step che una macchina con $m$ esegue prima di haltare. \\
Per entrambi consideriamo solo macchine che ricevono $\epsilon$ come input e haltano.

$S(m)$ non è computabile.

\section{2024-10-07}
\begin{gather*}
    (L,<)\subseteq (\Sigma^*,>) \\
    L\in RE \setminus R \\
    m_L
\end{gather*}

\section{Proprietà di una TM}
Una \textit{Proprietà} di una Turing machine è una qualsiasi funzione binaria (decision function) sulla macchina.
\begin{align*}
    HALT_\epsilon: TM \mapsto \{0,1\}
\end{align*}
Un esempio è Halt. Altri sono:
\begin{enumerate}
    \item $m$ has 10 states (Computable)
    \item $m$ decides prime numbers (Specification)
    \item $m$ recognizes halting TMs (Semantica)
    \item $m$ decides halting TMs (Computable perché è sempre \textit{False}. Triviale)
\end{enumerate}

\begin{callout}{Riconoscere vs Decidere}
    Una macchina di Turing \textit{Riconosce} qualcosa se conferma qualcosa ("risponde si"). Ma non ha un comportamento stabilito in caso contrario \\
    Una macchina \textit{Decide} qualcosa se risponde "si" o "no" in maniera definitiva
\end{callout}
Quindi una proprietà "P" \textbf{decide} un set di Turing Machines.
\begin{align*}
    P:TM\mapsto\{0,1\}
\end{align*}

\paragraph{Triviale}
Una proprietà $P$ è \textit{triviale} se $P=\emptyset$ o $P=TM$

\paragraph{Specification}
Boh °¬°

\paragraph{Semantic}
Ogni macchina di Turing può essere vista come
\begin{align*}
    m(s) = \begin{cases}
        1 \\
        \text{anything else} \\
        \infty
    \end{cases}
\end{align*}
Quindi possiamo dire che ogni macchina di Turing riconosce un linguaggio $L(m) = \{s\in\Sigma^*: m(s)=1\}$

Una proprietà è \textit{Semantica} se.
\begin{align*}
    \forall m_1,m_2\in TM. L(m_1)=L(m_2) \implies P(m_1)=P(m_2)
\end{align*}
Se le due macchine compiono lo stesso lavoro (riconoscono lo stesso linguaggio): O entrambe hanno la proprietà, o nessuna delle due la ha.

\begin{align*}
    P(m) = "\text{All strings recognized by $m$ have an even length}"
\end{align*}
La macchina che riconosce solo la stringa vuota ($\epsilon$) ha questa proprietà. Questo perché tutte le stringhe che vengono riconosciute da questa macchina (solo 1) hanno lunghezza $0$, che è pari.

\subsection{Teorema di Rice}
Se una proprietà è sia \textit{semantica} che \textit{non triviale} allora è \textbf{undecidable}

\paragraph{Prova per assurdo}
Sia $P$ semantica e non triviale. Deve esserci almeno una macchina $m_p$ per cui la proprietà sia vera (altrimenti sarebbe triviale)
\begin{equation*}
    m_p\in TM\ s.t.\ P(m_p)=1
\end{equation*}
Without loss of generality: $L(m)=\emptyset\implies P(m)=0$ Le macchine che riconoscono l'insieme vuoto non hanno la proprietà $P$.

Supponiamo per assurdo che $P$ sia decidibile. Quindi
\begin{equation*}
    \exists \mathcal{P} \in TM\ s.t.\ \forall m: \mathcal{P}(m)=P(m)
\end{equation*}
Esiste una macchina $\mathcal{P}$ che decide la proprietà $P$.

Abbiamo poi la macchina $HALT:\ TM\times\Sigma^*\mapsto \{0,1\}$ che decide se una certa macchina halta con un certo input.

Prendiamo poi una macchina qualsiasi $n\in TM$. Ovviamente possiamo ottenere $\mathcal P(\floor{n})$.
La macchina prende un input $t$ e:
\begin{algorithm}
    \caption{n}
    save $t$ on a separate tape\;
    Put $s$ on the input tape\;
    run $m(s)$\;
    restore original input $t$\;
    run $m_p(t)$
\end{algorithm}

\begin{align*}
    P(m_{ms}) = \begin{cases}
        0 & m(s)=\infty \\
        m_p(t) & m(s)\neq\infty
    \end{cases}
\end{align*}

\begin{align*}
    m(s)=\infty &\implies L(n_{ms})=\emptyset \\
    m(s)\neq\infty &\implies L(n_{ms})=L(m_p)\implies P(n_{ms}=P(m_p) = 1
\end{align*}
Quindi questa macchina risolverebbe l'halting problem. Questo è ovviamente assurdo e prova la tesi.

\section{Random String}
Qual'è la definizione di una stringa random? Potremmo dire che una stringa è casuale se ogni simbolo ha la stessa probabilità di apparire in ogni posizione. Ma data una determinata stringa, è possibile determinare se sia stata generata tramite un processo casuale o con intento?

Per esempio $S_0=000000$ non sembra casuale, ma potrebbe esserlo. $S_1=01101001010010$ invece sembra più "casuale" ma potrebbe essere generato secondo una regola precisa.

$S_0$ è facilmente comprimibile. Possiamo dire "è composta da 9 $0$" (\textit{Run-length encoding}). Arrivano quindi in considerazione i concetti di entropia e quantità di informazione.

Diciamo quindi che una stringa è \textit{casuale} quando non può essere compressa (o non può essere compressa molto). Questo è ovviamente soggetto a eccezioni, come il caso che si tiri 100 volte testa con una moneta. \\
Questa definizione però si basa pesantemente sulla definizione di un "algoritmo di compressione".

\begin{callout}{}
    Useremo intercambiabilmente il termine \textit{incomprimibile} e \textit{casuale}. \\
    Assumeremo anche di trattare solo algoritmo lossless.
\end{callout}

\subsection{Compression Algorithm}
Un algoritmo di compressione prende una stringa $s$ e genera una descrizione di $s$ più corta di $s$ stesso.
Questo implica ovviamente l'esistenza di un processo di \textit{decompressione} simmetrico a quello di compressione.

\begin{align*}
    & S\in\Sigma^* \\
    & |s| = l \\
    & \exists t \in \Sigma^*\ s.t\ |t|<l \\
    & \exists \underbrace{m}_{unzip}. m(\underbrace{t}_{zipped}) = \underbrace{s}_{original}
\end{align*}
Ci stiamo affidando a una macchina di decompressione $m$, ma cosa sappiamo riguardo all'efficenza di $m$?

\subsection{Kolmogorov}
Consideriamo la dimensione non solo di $t$ ma anche della macchina $m$ che decomprime $t$. Questo equivale a avere un "self expanding executable file".

\begin{callout}{}
    Immagina di scaricare un file compresso in un formato sconosciuto e di dover anche scaricare un programma per la decompressione del suddetto file. \\ La dimensione del programma di estrazione dovrebbe essere inclusa nella dimensione totale del download.
\end{callout}

Per definire la dimensione di $m$ fixiamo una macchina universale $U$.

\begin{align*}
    & S\in\Sigma^* \\
    & |s| = l \\
    & \underbrace{(m,t)}_{description\ of\ s}\ s.t\ U(m,t)=s
\end{align*}

\paragraph{Ottimalità} ovviamente a noi interessa la coppia $(m,t)$ più piccola possibile (quella "ottimale") che riproduca $s$ alla fine. \\
Un caso triviale sarebbe la macchina che copia un input e l'input originale. Questo ovviamente non è ottimale.

\subsection{"Most strings are incompressible"}
\begin{gather*}
    \Sigma=\{0,1\} \\
    S = \Sigma^{100} \\
    |S| = |\Sigma^{100}| = 2^{100}
\end{gather*}
Quante stringhe $s\in\Sigma^{100}$ sono comprimibili almeno del $10\%$? ($C(s)=t\quad |t|\leq 90$)

Perché esista un algoritmo di compressione deve esistere alche un algoritmo di decompressione. 

\begin{gather*}
    t\in\bigcup_{i=0}^{90}\Sigma^i = T \\
    |T| = \left|\bigcup_{i=0}^{90}\Sigma^i\right| = \sum_{i=0}^{90} 2^i = 2^{91}-1 \\
    \frac{|T|}{|S|} = \frac{1}{512}
\end{gather*}

Quindi una stringa su $512$ di tutte quelle di lunghezza $100$ o meno è comprimibile di almeno il $10\%$. Questo a prescindere dall'algoritmo di compressione.

Quindi "most strings are random".

Fortunatamente, le stringhe che ci interessano di solito non sono random, quindi sono comprimibili.

\subsection{Kolmogorov complexity}
\begin{gather*}
    D_{s,u} = \{(m,t)\in\Sigma^*\ s.t\ U(m,t)=s\} \\
    K_U(s) = \min_{(m,t)\in D_{s,u}}(|m|+|t|)
\end{gather*}
Chiamiamo la \textit{Complessità di Kolmogorov} di una stringa $s$ (con rispetto a una macchina universale $U$) la lunghezza minima di $m,t$ tali che $U(m,t)=s$. \\
Questa definizione di \textit{complessità} ovviamente dipende dalla macchina universale $U$. Se volessimo prendere anche $U$ in considerazione?

Supponiamo di avere due macchine universali $U$ e $V$. Possiamo prendere una descrizione in $U$ e usarla in $V$ aggiungendo dell'overhead.
\begin{gather*}
    V(u, (m,t)) = U(m,t) = s
\end{gather*}
Una caratteristica particolare è che l'overhead è sempre lo stesso indipendentemente da $m$ e $t$. È sempre la stessa $u$.

\begin{gather*}
    \forall U,V\in UTM \exists C_{U,V} = |u_v|\footnotemark\\
    K_V(s) \leq K_U(s) + C_{U,V} \\
    K_V = O(K_U) 
\end{gather*}
Le due rappresentazioni sono asintoticamente equivalenti. 
\footnotetext{representation of $u$ in $v$} 

\subsection{La Kolmogorov Complexity È Uncomputable}
Prendiamo una macchina universale $U$. $K_U$ \textbf{non} è computable.

Prendiamo la frase \center
\textit{"The smallest number that cannot be defined with less than thirteen words"}
\flushleft
Questa frase è un paradosso, perché se trovassimo questo numero la frase gli si applicherebbe (ed essendo una frase di 12 parole lo renderebbe definibile con meno di 13 parole).

Ora dobbiamo trovare una maniera formale di dimostrare la con computabilità della complessità di Kolmogorov utilizzando questo paradosso.
\begin{itemize}
    \item number $to$ string
    \item defined $to$ Kolmogorov complexity
    \item words $to$ symbols
\end{itemize}

\begin{gather*}
    K_U(s) \text{The minimum \# of symbols that define $s$ (wrt $U$)}
\end{gather*}

\paragraph{Prova per assurdo}
Supponiamo di avere una macchina $m_{K,U} \in TM$ tale che $\forall s\in\Sigma^* m_{K,U}(s) = K_U(s)$
\begin{algorithm}
    \caption{$m$}
    \ForAll{$s\in\Sigma^*$}{
        \If{$K_U(s)>|\floor{m_{k,u}}|+1000000\footnotemark[1]$}{
            output $s$ and $HALT$\;
        }
    }
\end{algorithm}
\footnotetext{Costante di overhead per l'esecuzione dell'algoritmo stesso}

\begin{gather*}
    |\floor{m}| \leq |\floor{m_{ku}}| + 1000000
\end{gather*}

\section{Reduction}
Supponiamo di avere due linguaggi $L_1, L_2 \subseteq \Sigma^*$, e una funzione $f:\Sigma^*\to \Sigma^*$. \\
Supponiamo poi che la funzione $f$ mappi elementi di $L_1$ in $L_2$ ($x\in L_1 \iff f(x)\in L_2$).\\
Se sappiamo che $L_2$ è ricorsiva, possiamo dire nulla su $L_1$? Si, sappiamo che $L_1$ è recursive, in quanto possiamo costruire $m_1(x)=m_2(f(x))$.

Chiamiamo una funzione $f$ una \textit{"riduzione"} se si comporta un questo modo ($x\in L_1 \iff f(x)\in L_2$). E \textit{"Turing riduzione"} se $f$ è computabile con una macchina di Turing. \\
Due linguaggi sono \textit{"riducibili"} o \textit{"Turing riducibili"} se esiste una $f$ da un linguaggio all'altro.

\subsection{Proprietà}
Se $L_1$ può essere ridotto a $L_2$:
\begin{itemize}
    \item $L_2\ \text{recursive}\implies L_1\ \text{recursive}$
    \item $L_1\cancel{\text{recursive}} \implies\ L_2\ \cancel{\text{recursive}}$
    \item $L_2\ RE \implies L_1\ RE$
\end{itemize}

\section{Unione di $RE\setminus R$}
Supponiamo di avere due linguaggi $L_1,L_2\in RE\setminus R$. \\
Sappiamo $L_{12}=L_1\cup L_2 \in RE$. Basta runnare $m_1$ e $m_2$ assieme e se una delle due halta haltiamo $m_{12}$.\\
Ma possiamo dire se $L_12$ in $RE$ o in $RE\setminus R$? No. Non possiamo imporre alcun constrain sul fatto che sia \textit{recursive}.

\begin{callout}{Proof}
    Questo è provato definendo $E$ l'insieme di tutte le stringhe rappresentanti TM con un numero pari di stati. Poi definiamo $O$ l'insieme di tutte le macchine con numero dispari di stati.

    Ora $L_1=E\cup HALT_\epsilon$ e $L_2=O\cup HALT_\epsilon$.
\end{callout}

\section*{Esercizio}
\begin{gather*}
    L \in \Sigma^*\ \text{recursive} \\
    TM\ m\ \text{Partially decides }L \\
    \forall x\in\Sigma^* m(x)=\infty \vee m(x) = \begin{cases}0 & x\not\in L \\ 1 & x\in L\end{cases} \\
    \begin{array}{c | c c c c c}
        x & \epsilon & 0 & 1 & 00 & 01 \\
        \hline
        m(x) & 0 & \infty & 1 & 0 & \infty
    \end{array}
\end{gather*}
Possiamo dire che una macchina $m$ \textit{decide parzialmente} $L$ se: "Quando halta da la risposta giusta". Trivialmente la macchina che non halta mai decide parzialmente tutti i linguaggi.

\paragraph{domanda} La proprietà "partially decides $L$" è decidibile? \\
Iniziamo vedendo se possiamo usare il teorema di Rice.
\subparagraph{La proprietà è triviale?} No, possiamo facilmente creare una macchina che non soddisfa la proprietà.
\subparagraph{La proprietà è semantica?} No. Quindi non possiamo usare Rice. \\
Dimostrazione che la proprietà non è semantica.
\begin{gather*}
    L = \{0, 01\} \\
    \begin{array}{c|ccccc}
        x & \epsilon & 0 & 1 & 00 & 01 \\
        \hline
        m_1(x) & \infty & \infty & 1 & \infty & \infty \\
        m_2(x) & 0 & 0 & 1 & 0 & 0 \\
    \end{array}
\end{gather*}
Le due macchine riconoscono lo stesso linguaggio $L'=\{1\}$. Ma la prima ha la proprietà, mentre la seconda no.$_\square$

\paragraph{Dimostrazione che $P$ non è decidibile}
Questo può essere dimostrato con la stessa prova che abbiamo usato per dimostrare il teorema di Rice. Ovvero riducendo la macchina $H$ che risolve l'halting problem a quella che decide la proprietà $P$.

$(m,t)\mapsto n_{m,t}(x)$
\begin{algorithm}
    \caption{n}
    move $x$ on aux tape\;
    replace it with $t$\;
    run $m_m$(t)\;
    restore original input $x$\;
    run $m_A(x)$
\end{algorithm}

\section*{esercizio}
\begin{align*}
    & \Sigma = \{\text{\textvisiblespace},0,1\} \\
    & Q = \{q_0, q_1, \dots, q_n\} \\
    & q_0\ \text{initial state} \\
    & f: \Sigma\times Q \to \Sigma\times Q\times \{\leftarrow,\rightarrow\}
\end{align*}

Vediamo come possiamo "modificare" una TM.
\begin{enumerate}
    \item Se la posizione iniziale della TM fosse sconosciuta (quindi la posizione dell'input) possiamo creare una macchina che si posiziona all'inizio dell'input? Si. Dovrebbe fare la spola a destra e sinistra spostando dei marker fino a che non trova l'input.
    \item Ipotizziamo che la macchina abbia delle celle "difettose". $\Sigma' = \Sigma\cup\{x\}$. Possiamo modificare $Q$ e $f$ per ignorare le celle difettose?
\end{enumerate}

Per ogni stato $q_n$ creiamo 4 stati $q_{nl1},q_{nl2}, q_{nr1},q_{nr2}$
\begin{align*}
    \begin{array}{c|c|c|c|c}
                    & x & \tvs & 0 & 1 \\
        \hline
        q_{nl1} & x,q_{nl1},\leftarrow & \tvs,q_{nl2},\rightarrow & 0,q_{nl2},\rightarrow & 0,q_{nl2},\rightarrow \\
        q_{nl2} & x,q_n,\leftarrow & \tvs,q_n\leftarrow & 0,q_n\leftarrow & 1,q_n\leftarrow \\
        q_{nr1} & x,q_{nr1},\rightarrow & \tvs,q_{nr2},\leftarrow & 0,q_{nr2},\leftarrow & 0,q_{nr2},\leftarrow \\
        q_{nr2} & x,q_n,\rightarrow & \tvs,q_n\rightarrow & 0,q_n\rightarrow & 1,q_n\rightarrow \\
    \end{array}
\end{align*}
Dopodiché, nella funzione di transizione originale, sostituiamo ogni regola del tipo $(\sigma,q_n,\leftarrow)$ con $(\sigma,q_{nl1},\leftarrow)$ e ogni regola del tipo $(\sigma,q_n,\rightarrow)$ con $(\sigma,q_{nr1},\rightarrow)$

\section{Computational Complexity}
Da ora in poi prenderemo in considerazione solo linguaggi ricorsivi. Quindi c'è sempre una macchina di Turing che li riconosce.
\begin{gather*}
    L \text{ is recursive } \\
    \exists m: L(m)=L \wedge \forall s\in \Sigma^* m(s)<\infty
\end{gather*}

Data una stringa $s\in\Sigma^*$, $t_m:\Sigma^*\mapsto\mathbb{N}$ è una funzione che mappa $s$ al \textit{numero di step} svolti da $m(s)$ prima di interrompersi.

$T_m:\N\mapsto\N:n\mapsto \max_{|s|=n} t_m(s)$ ci dice il numero di step in relazione alla \textit{dimensione} dell'input.

\begin{callout}{es}
    Prendiamo la funzione $f$ che decide se un numero è pari o no 
    \begin{align*}
        &\Sigma=\{\tvs,0,1\} \\
        f:&\N\mapsto\{0,1\} \\
          &n\mapsto \begin{cases}
              1 & even \\
              0 & odd
          \end{cases}
    \end{align*}
    Assumiamo che i numeri siano rappresentati in binario e che $m$ si comporti così:
    \begin{enumerate}
        \item scorri a destra fino a fine del numero (n steps)
        \item fai un controllo sull'ultimo bit (1 step)
        \item scorri a sinistra cancellando il numero (n steps)
        \item scrivi l'output (1 step)
    \end{enumerate}
    $T_m(\underbrace{n}_{\text{size of representation of $m$}})=2n+2 = O(n)$
\end{callout}

\subsection{Deterministic Time}
\begin{align*}
    DTIME(f) = \{L\subseteq\Sigma^*:\exists m. L(m)=L\wedge T_m(n)=O(f(n))\}
\end{align*}

\subsection{Polynomial Languages}
\begin{align*}
    \mathbb{P} = \bigcup_{k=0}^\infty DTIME(n^k)
\end{align*}

\subparagraph{Input types}
Se il problema che stiamo affrontando non prende espressamente stringhe come input dobbiamo escogitare un encoding per l'input in maniera che una Turing machine possa lavorarci.

Nel caso di un grafo possiamo decidere di usare una matrice di adiacenza.
\begin{align*}
    A&\in\{0,1\}^{n\times n} \\
    A_{ij} &= \begin{cases}
        1 & \{i,j\} \in E \\
        0 & else
    \end{cases}
\end{align*}
$\text{input size} = O(n^2)$

\subsection{Prime numbers}
\begin{algorithm}
    \caption{is\_prime}
    function is\_prime($n\in\N$) \{\;
        \For{$i=2\dots\sqrt{n}$}{
            \If{$n\%i==0$}{
                reject\;
            }
        }
        accept\;
    \}
\end{algorithm}

La dimensione dell'input è $|s| = O(\log n)$. Quindi $n=O(2^{|s|})$. $\sqrt{n}=O(2^{|s|/2})$. I numeri sono esponenzialmente proporzionali al numero di bit usati per rappresentarli. Quindi questo algoritmo per decidere se un numero è primo non è polinomiale.

Ci sono algoritmi più sofisticati che possono decidere se un numero è primo in tempo polinomiale con rispetto alla quantità di bit usati.

\subparagraph{Satisfiability}
Date $n$ variabili booleane $x_1,\dots,x_n$, una congiunzione di disgiunzioni $(x\wedge x\wedge\dots\wedge x) \vee (x\wedge x\wedge\dots\wedge x)$

\begin{itemize}
    \item term(atom): a variable $x$ or its negation
    \item clause: $c_j=\vee{i=1}^{n_j} t_{ij}$
    \item formula: $\wedge_{j=1}^m c_j$
\end{itemize}

Una formula è \textit{soddisfacibile} se esiste una combinazione di variabili tale per cui risulta vera.\\
Il problema SAT è trovare questa combinazioni (almeno una di queste combinazioni).

Non abbiamo un algoritmo che risolva questo problema in tempo polinomiale. Quindi non possiamo dire se SAT sia in $\mathbb{P}$ o meno.

\subsection{Integer Linear Programming}

\subsection{Certificazione}
\textit{Clique}, \textit{D ILP}, e \textit{SAT} non hanno algoritmi polinomiali che trovino una soluzione. Ma, data una soluzione, verificare che essa sia valida o meno è molto semplice (polinomiale). Quindi la difficoltà sta nel fare questa semplice prova su un numero smisurato di possibili soluzioni.

\begin{callout}{Problemi difficili da controllare}
    Non tutti i problemi condividono questa proprietà. Prendiamo l'esempio di un gioco da tavolo (come scacchi) e di voler decidere se la board è a favore di un giocatore o dell'altro. L'input del problema è limitato, essendo ristretto alla rappresentazione della board, ma ogni decisione del giocatore vincente non può essere realisticamente fatta senza simulare ogni possibile evoluzione del gioco.\\
    Questo è ovviamente computazionalmente complesso (esponenziale), a discapito dell'input limitato.
\end{callout}

Definiamo più formalmente questa proprietà.
\begin{gather*}
    \forall x \in L \\
    \exists M\text{ verifying machine} \\
    \exists \underbrace{m}_\text{certificate} \in \Sigma^*: M(x,m) = 1 \\
    \exists p,q\text{ polinomiale}. |m|<p(|x|) \wedge t_m(x,m)\leq q(|x|)
\end{gather*}

\end{document}
